import torch
import torch.nn as nn
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
import torch.optim as optim
from model import MobileNetV2
import os
import json
import torchvision.models.mobilenet
import matplotlib.pyplot as plt
import numpy as np


# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

data_transform = {
    "train" : transforms.Compose([transforms.RandomResizedCrop(224),   # éšæœºè£å‰ª
                                  transforms.RandomHorizontalFlip(),   # éšæœºç¿»è½¬
                                  transforms.ToTensor(),
                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
    "val" : transforms.Compose([transforms.Resize(256),      # é•¿å®½æ¯”ä¸å˜ï¼Œæœ€å°è¾¹é•¿ç¼©æ”¾åˆ°256
                                transforms.CenterCrop(224),  # ä¸­å¿ƒè£å‰ªåˆ° 224x224
                                transforms.ToTensor(),
                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}

# è·å–æ•°æ®é›†æ‰€åœ¨çš„æ ¹ç›®å½•
data_root = os.path.abspath(os.getcwd())
# è·å–åŠ¨ç‰©æ•°æ®é›†è·¯å¾„
image_path = data_root + "/data_set/"

# åŠ è½½æ•°æ®é›†
train_dataset = datasets.ImageFolder(root=image_path + "/train",
                                     transform=data_transform["train"])

# è·å–è®­ç»ƒé›†å›¾åƒæ•°é‡
train_num = len(train_dataset)

# è·å–åˆ†ç±»çš„åç§°
animal_list = train_dataset.class_to_idx
print(f"æ•°æ®é›†ç±»åˆ«: {animal_list}")

# é‡‡ç”¨éå†æ–¹æ³•ï¼Œå°†åˆ†ç±»åç§°çš„keyä¸valueåè¿‡æ¥
cla_dict = dict((val, key) for key, val in animal_list.items())

# å°†å­—å…¸cla_dictç¼–ç ä¸ºjsonæ ¼å¼
json_str = json.dumps(cla_dict, indent=4)
with open("class_indices.json", "w") as json_file:
    json_file.write(json_str)

batch_size = 16
train_loader = DataLoader(train_dataset,
                          batch_size=batch_size,
                          shuffle=True,
                          num_workers=0)

validate_dataset = datasets.ImageFolder(root=image_path + "/val",
                                        transform=data_transform["val"])
val_num = len(validate_dataset)
validate_loader = DataLoader(validate_dataset,
                             batch_size=batch_size,
                             shuffle=True,
                             num_workers=0)

print(f"è®­ç»ƒé›†å›¾åƒæ•°é‡: {train_num}")
print(f"éªŒè¯é›†å›¾åƒæ•°é‡: {val_num}")

# å®šä¹‰æ¨¡å‹
net = MobileNetV2(num_classes=len(cla_dict))   # å®ä¾‹åŒ–æ¨¡å‹
net.to(device)

# å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡
model_weight_path = "./CV/mobilenet_v2-b0353104.pth"
if os.path.exists(model_weight_path):
    print("åŠ è½½é¢„è®­ç»ƒæƒé‡...")
    pre_weights = torch.load(model_weight_path, map_location=device)
    # åˆ é™¤åˆ†ç±»æƒé‡
    pre_dict = {k: v for k, v in pre_weights.items() if "classifier" not in k}
    missing_keys, unexpected_keys = net.load_state_dict(pre_dict, strict=False)
    print(f"ç¼ºå¤±çš„é”®: {len(missing_keys)}, æ„å¤–çš„é”®: {len(unexpected_keys)}")
    
    # å†»ç»“é™¤æœ€åå…¨è¿æ¥å±‚ä»¥å¤–çš„æ‰€æœ‰æƒé‡
    for param in net.features.parameters():
        param.requires_grad = False
    print("å·²å†»ç»“ç‰¹å¾æå–å±‚")
else:
    print("æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")

loss_function = nn.CrossEntropyLoss()   # å®šä¹‰æŸå¤±å‡½æ•°
optimizer = optim.Adam(net.parameters(), lr=0.0001)  # å®šä¹‰ä¼˜åŒ–å™¨

# ç”¨äºå­˜å‚¨è®­ç»ƒå†å²
train_losses = []
train_accuracies = []
val_accuracies = []
epochs_list = []

# è®¾ç½®å­˜å‚¨æƒé‡è·¯å¾„
save_path = './CV/mobilenetV2.pth'
best_acc = 0.0
num_epochs = 100

print(f"\nå¼€å§‹è®­ç»ƒï¼Œå…±{num_epochs}è½®...")

for epoch in range(num_epochs):
    print(f"\n=== Epoch {epoch + 1}/{num_epochs} ===")
    
    # è®­ç»ƒé˜¶æ®µ
    net.train()
    running_loss = 0.0
    train_correct = 0
    train_total = 0
    
    for step, data in enumerate(train_loader, start=0):
        # è·å–æ•°æ®çš„å›¾åƒå’Œæ ‡ç­¾
        images, labels = data
        
        # å°†å†å²æŸå¤±æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = net(images.to(device))
        loss = loss_function(outputs, labels.to(device))
        
        # åå‘ä¼ æ’­å’Œä¼˜åŒ–
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡ä¿¡æ¯
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels.to(device)).sum().item()
        
        # æ‰“å°è®­ç»ƒè¿›åº¦
        rate = (step + 1) / len(train_loader)
        a = "*" * int(rate * 50)
        b = "." * int((1 - rate) * 50)
        print(f"\rè®­ç»ƒè¿›åº¦: {int(rate * 100):3d}%[{a}->{b}] Loss: {loss.item():.4f}", end="")
    
    # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
    train_acc = train_correct / train_total
    avg_train_loss = running_loss / len(train_loader)
    
    # éªŒè¯é˜¶æ®µ
    net.eval()
    val_correct = 0
    val_total = 0
    
    with torch.no_grad():
        for data_test in validate_loader:
            test_images, test_labels = data_test
            outputs = net(test_images.to(device))
            _, predicted = torch.max(outputs, 1)
            val_total += test_labels.size(0)
            val_correct += (predicted == test_labels.to(device)).sum().item()
    
    val_acc = val_correct / val_total
    
    # ä¿å­˜è®­ç»ƒå†å²
    epochs_list.append(epoch + 1)
    train_losses.append(avg_train_loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_acc > best_acc:
        best_acc = val_acc
        torch.save(net.state_dict(), save_path)
        print(f"\nâœ“ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜! éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
    
    # æ‰“å°epochç»“æœ
    print(f"\nEpoch {epoch + 1:3d}: è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
    
    # # æ¯10ä¸ªepochç»˜åˆ¶ä¸€æ¬¡å›¾è¡¨
    # if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1:
    #     plot_training_history(epochs_list, train_losses, train_accuracies, val_accuracies, epoch + 1)

print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}")

def plot_training_history(epochs, train_losses, train_accs, val_accs, current_epoch):
    """ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨"""
    
    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    fig.suptitle(f'è®­ç»ƒå†å² (Epoch {current_epoch})', fontsize=16, fontweight='bold')
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    ax1.plot(epochs, train_losses, 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±', marker='o', markersize=4)
    ax1.set_title('è®­ç»ƒæŸå¤±å˜åŒ–', fontsize=14, fontweight='bold')
    ax1.set_xlabel('è½®æ¬¡ (Epoch)', fontsize=12)
    ax1.set_ylabel('æŸå¤±å€¼ (Loss)', fontsize=12)
    ax1.grid(True, alpha=0.3)
    ax1.legend(fontsize=11)
    
    # è®¾ç½®æŸå¤±å›¾çš„æ ·å¼
    ax1.spines['top'].set_visible(False)
    ax1.spines['right'].set_visible(False)
    
    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(epochs, train_accs, 'g-', linewidth=2, label='è®­ç»ƒå‡†ç¡®ç‡', marker='s', markersize=4)
    ax2.plot(epochs, val_accs, 'r-', linewidth=2, label='éªŒè¯å‡†ç¡®ç‡', marker='^', markersize=4)
    ax2.set_title('å‡†ç¡®ç‡å˜åŒ–', fontsize=14, fontweight='bold')
    ax2.set_xlabel('è½®æ¬¡ (Epoch)', fontsize=12)
    ax2.set_ylabel('å‡†ç¡®ç‡ (Accuracy)', fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.legend(fontsize=11)
    ax2.set_ylim(0, 1)
    
    # è®¾ç½®å‡†ç¡®ç‡å›¾çš„æ ·å¼
    ax2.spines['top'].set_visible(False)
    ax2.spines['right'].set_visible(False)
    
    # æ·»åŠ æœ€æ–°æ•°å€¼æ ‡æ³¨
    if len(epochs) > 0:
        latest_epoch = epochs[-1]
        latest_loss = train_losses[-1]
        latest_train_acc = train_accs[-1]
        latest_val_acc = val_accs[-1]
        
        # åœ¨æŸå¤±å›¾ä¸Šæ ‡æ³¨æœ€æ–°å€¼
        ax1.annotate(f'{latest_loss:.4f}', 
                    xy=(latest_epoch, latest_loss), 
                    xytext=(10, 10), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
        
        # åœ¨å‡†ç¡®ç‡å›¾ä¸Šæ ‡æ³¨æœ€æ–°å€¼
        ax2.annotate(f'è®­ç»ƒ: {latest_train_acc:.4f}', 
                    xy=(latest_epoch, latest_train_acc), 
                    xytext=(10, 10), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
        
        ax2.annotate(f'éªŒè¯: {latest_val_acc:.4f}', 
                    xy=(latest_epoch, latest_val_acc), 
                    xytext=(10, -20), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_filename = f'./CV/training_history_epoch_{current_epoch:03d}.png'
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š è®­ç»ƒå›¾è¡¨å·²ä¿å­˜: {plot_filename}")
    
    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()
    plt.close()

def save_training_log(epochs, train_losses, train_accs, val_accs):
    """ä¿å­˜è®­ç»ƒæ—¥å¿—åˆ°æ–‡ä»¶"""
    log_filename = './CV/training_log.txt'
    
    with open(log_filename, 'w', encoding='utf-8') as f:
        f.write("=== MobileNetV2 åŠ¨ç‰©åˆ†ç±»è®­ç»ƒæ—¥å¿— ===\n\n")
        f.write(f"è®­ç»ƒè½®æ¬¡: {len(epochs)}\n")
        f.write(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(val_accs):.4f}\n")
        f.write(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.4f}\n")
        f.write(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {train_accs[-1]:.4f}\n")
        f.write(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accs[-1]:.4f}\n\n")
        
        f.write("è¯¦ç»†è®­ç»ƒè®°å½•:\n")
        f.write("Epoch\tTrain_Loss\tTrain_Acc\tVal_Acc\n")
        f.write("-" * 50 + "\n")
        
        for i, epoch in enumerate(epochs):
            f.write(f"{epoch:3d}\t{train_losses[i]:.6f}\t{train_accs[i]:.6f}\t{val_accs[i]:.6f}\n")
    
    print(f"ğŸ“ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_filename}")

# æœ€ç»ˆç»˜åˆ¶å®Œæ•´çš„è®­ç»ƒå†å²
plot_training_history(epochs_list, train_losses, train_accuracies, val_accuracies, num_epochs)

# ä¿å­˜è®­ç»ƒæ—¥å¿—
save_training_log(epochs_list, train_losses, train_accuracies, val_accuracies)

print("ğŸ‰ æ‰€æœ‰è®­ç»ƒä»»åŠ¡å®Œæˆ!")